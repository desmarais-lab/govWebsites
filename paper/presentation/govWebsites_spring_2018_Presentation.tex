\documentclass[12pt]{beamer}
\setbeamertemplate{navigation symbols}{}
%\usepackage[latin1]{inputenc}
\usepackage{pgfplots}
\usepackage{adjustbox}
\usepackage{graphicx}
%\usepackage{draftwatermark}
\usepackage{tikz}
\usepackage{colortbl}
\usepackage{subfigure}
%\usetheme{Amsterdam}
\usecolortheme{default}
\title[]{Government websites as data: A methodological pipeline for
collection, processing, and text analysis}
\author{Markus Neumann \\ Fridolin Linder \\ Bruce Desmarais}
\institute{The Pennsylvania State University}
\date{January 6, 2018}

\makeatletter
\defbeamertemplate*{footline}{myminiframes theme}
{%
	\begin{beamercolorbox}[colsep=1.5pt]{upper separation line foot}
	\end{beamercolorbox}
	\hbox{%
		\begin{beamercolorbox}[wd=.1\paperwidth,ht=2.5ex,dp=1.125ex,%
			leftskip=.3cm,rightskip=.3cm,center]{title in head/foot}%
			{\usebeamerfont{author in head/foot}\usebeamercolor[fg]{author in head/foot}}{\insertframenumber}%/\inserttotalframenumber}%
		\end{beamercolorbox}%
		\begin{beamercolorbox}[wd=.75\paperwidth,ht=2.5ex,dp=1.125ex,%
			leftskip=.3cm,rightskip=.3cm plus1fil,center]{title in head/foot}%
			\leavevmode{\usebeamerfont{title in head/foot}\insertshorttitle}%
		\end{beamercolorbox}%
		\begin{beamercolorbox}[wd=.15\paperwidth,ht=2.5ex,dp=1.125ex,%
			leftskip=.3cm,rightskip=.3cm plus1fil,center]{title in head/foot}%
			{\usebeamerfont{author in head/foot}\usebeamercolor[fg]{author in head/foot}}%\insertshortauthor}
		\end{beamercolorbox}%
	}%
	\begin{beamercolorbox}[colsep=1.5pt]{lower separation line foot}
	\end{beamercolorbox}
}
\makeatother

\begin{document}

\section{Introduction}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Presented at SPSA}
	\textbf{Data Collection} \hspace{2mm} $\rightarrow$ \hspace{2mm} \textbf{Preprocessing} \hspace{2mm} $\rightarrow$ \hspace{2mm} \textbf{Analysis}
\begin{columns}
	\column{0.33\textwidth}
	%Data Collection
	\vspace{5mm}
	\begin{itemize}
		\item Identify URLs
		\item Verify URLs (browser automation)
		\item Download websites
		\item Determine file type
		\item Convert to txt
	\end{itemize}		
	\column{0.33\textwidth}
	%Preprocessing
	\vspace{5mm}
	\begin{itemize}
		\item Remove punctuation, dates, etc.
		\item To lowercase
		\item Boilerplate removal
		\item Spellchecking
		\item Lemmatization \\ (city \& cities = city)
	\end{itemize}
	\column{0.33\textwidth}
	%Analysis
	\vspace{5mm}
	\begin{itemize}
		%\item Hierarchical clustering
		\item Fightin' Words
		\item Structural topic model
		%\begin{itemize}
		%	\item LDA
		%	\item STM
		%\end{itemize}
	\end{itemize}
\end{columns}
\end{frame}

\begin{frame}{Presented at SPSA}
\input{descriptiveStatsIN.tex}
\input{descriptiveStatsLA.tex}
\end{frame}

\begin{frame}{Presented at SPSA}
\begin{figure}
	\hfill
	\subfigure{\includegraphics[width=5cm, height = .7\textheight]{../figures/indiana_map.pdf}}
	\hfill
	\subfigure{\includegraphics[width=5cm, height = .7\textheight]{../figures/louisiana_map.pdf}}
\end{figure}
\end{frame}

\begin{frame}{Presented at SPSA}
	\input{fightinwordsIN.tex}
\end{frame}

\begin{frame}{Presented at SPSA}
\input{stmTopWordsINDem.tex} %../tables/stmTopWordsINDem.tex
\end{frame}

\begin{frame}{Presented at SPSA}
\input{stmTopWordsINRep.tex} %../tables/stmTopWordsINRep.tex
\end{frame}

\begin{frame}{SPSA feedback}
\begin{itemize}
	\item overall quite positive
	\item there seems to be some demand in publican administration for this kind of research
	\item threshold of ten for duplicates
	\item the usual concerns with bag-of-words
	\item describe methods more clearly
	\item \textbf{``Does your method improve the external validity so greatly that the internal validity becomes less of a concern?''}
	\item comparison with non-partisan cities/websites
	\item city covariates
\end{itemize}
\end{frame}

\begin{frame}{Planned covariates}
\begin{itemize}
	\item population
	\item GDP per capita
	\item percent non-white
	\item City area
	\item democratic vote share/magnitude of victory
	\item log median house price
	\item (most of these are from Einstein \& Glick 2015)
\end{itemize}
\end{frame}

\begin{frame}{Since SPSA - ground truth test}
\begin{itemize}
	\item party manifestos (didn't work - not enough data)
	\item mayors' campaign websites (LA/IN - didn't work - not much data, and strange results)
	\item mayors' campaign websites (top 100 cities - worked somewhat)
\end{itemize}
{\renewcommand\normalsize{\tiny}%
	\small
	\input{../tables/groundtruth_bootstrapped.tex}}
\end{frame}

\begin{frame}{Since SPSA - extending the sample}
\begin{itemize}
	\item New York
	\item big cities
	\item Washington
	\item Oregon (unsuccessful)
	\item extended LA/IN (55 -> 165)
	\item 314 cities total, 230 downloaded so far
\end{itemize}
\end{frame}

\begin{frame}{wget and www}
\begin{itemize}
	\item www.townoflockport.com/ -- doesn't work
	\item http://townoflockport.com/ -- works
	\item inconsistent across websites
	\item solution: check every website with Selenium, record the url it redirects to
	\item currently re-scraping the 84 websites still missing
\end{itemize}
\end{frame}

\begin{frame}{Next steps: compression}
\begin{itemize}
	\item Since, so far, something has always gone wrong when adjusting file endings and converting files to text, I've always made zipped backups so far
	\item compression of millions of files of more than 1TB
	\begin{itemize}
		\item time
		\item some paths are too long
		\item some filenames have non-ascii characters
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}{Next steps: map}
\includegraphics[width=\linewidth, height = .99\textheight]{../figures/us_map.pdf}
\end{frame}

\begin{frame}{Next steps: covariates}
\begin{itemize}
	\item I already downloaded the above some time ago, but only for LA and IN
	\item this was already a little convoluted, I'll have to automate it for it to work with all states
	\item there is a problem with the census data:
\end{itemize}
\end{frame}

\begin{frame}{Next steps: covariates}
\begin{itemize}
	\item I already downloaded the above some time ago, but only for LA and IN
	\item this was already a little convoluted, I'll have to automate it for it to work with all states
	\item there is a problem with the census data:
\end{itemize}
\includegraphics[width=\linewidth]{census_problem.png}
\begin{itemize}
	\item Not a priority right now, need to finish all the document-related stuff first
\end{itemize}
\end{frame}

\begin{frame}{Next steps: optimize code}
\begin{itemize}
	\item preprocessing already took 4-5 hours for 25000 documents
	\item we currently have 1.3 million; this will get reduced a bit, but it will still be a huge increase
	\item the functions that aren't already vectorized are currently ``sapply'd''
	\item with this much data, parallelization is probably worth it (currently only hashtables, spellchecking and some other more computationally intensive stuff is parallelized)
	\item MAYBE it would be worth it to translate everything to quanteda - but unfortunately that won't work with the hashtables stuff
	\item fightin' words is pretty fast, but stm also took hours already
\end{itemize}
\end{frame}

\begin{frame}{Next steps: structural topic model}
\begin{itemize}
	\item currently we use separate models for IN, LA
	\item state fixed effects
	\item package has problems with overly complex models
	\item maybe use stm only for IN, LA, NY, WA, CA
\end{itemize}
\end{frame}

\end{document}
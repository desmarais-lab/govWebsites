{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 ArialMT;}
{\colortbl;\red255\green255\blue255;\red26\green26\blue26;\red26\green26\blue26;\red255\green255\blue255;
\red0\green0\blue0;}
{\*\expandedcolortbl;;\csgenericrgb\c10196\c10196\c10196;\cssrgb\c13333\c13333\c13333;\cssrgb\c100000\c100000\c100000;
\cssrgb\c0\c0\c0;}
\margl1440\margr1440\vieww14380\viewh10000\viewkind0
\deftab720
\pard\pardeftab720\qj\partightenfactor0

\f0\fs24 \cf2 \expnd0\expndtw0\kerning0
We thank the editor for recommending that we revise our manuscript and resubmit it as a note for 
\i Political Analysis
\i0 . Throughout the revision process, we have incorporated the feedback of the reviewers. In this memo we have separated the editor\'92s and reviewers\'92 comments into separate points. Under each point, we describe how we have revised the manuscript in response to the feedback provided. We generally agree with the criticisms offered, and think that the manuscript has improved substantially as a result of incorporating this feedback.
\b \cf3 \cb4 \
\pard\pardeftab720\sl220\partightenfactor0
\cf3 \
Editor\
\
E.1: 
\i\b0 \cf5 Having said all of that, I would welcome a de novo contribution in the form of a letter (per our guidelines) with the specific software details furnished in an appendix to be placed online if published (or preferably as an R package automating some of the decisions).\
\

\i0\b \cf3 Addressed:
\i\b0 \cf5 \

\i0 \cb1 \

\b \cf3 \cb4 E.2: 
\i\b0 \cf5 Of course this letter would have to be written such that there is a methodological contribution independent of the appendix. 
\i0 \cb1 \

\b \cf3 \cb4 \
Addressed: \
\
Reviewer 1
\b0 \uc0\u8232 \

\b R1.1: 
\i\b0 If pipeline is a research output, it should be made available (e.g. in form of an R-package) 
\i0\b \
\
Addressed:  
\b0 We have implemented and wrapped the core components of our pipeline in an R package, gov2text. The package will be publicly distributed on GitHub upon acceptance for publication. In Table 
\b \
\
R1.2:
\i\b0  I agree that extraction of plain text (body text extraction) is almost always the problem in online data collection, but author resort to manual coding and supervised machine learning to do the task. Since manual coding is not always the option, the authors should have tried to develop semi\'adsupervised or unsupervised method. Creation of such a tool is certanly a great contribution.\
\

\i0\b Addressed:   
\b0 We now introduce the boilerpipe algorithm for this purpose, which does not require the development of a corpus-specific classifier. 
\i \
\

\i0\b R1.3: 
\i\b0 I think the use of Selenium is appropriate because it replicates humans accessing website. However, I do not understand why the author used wget to download pages. There must be dynamic elements in the pages that are generated or inserted by javascript. I consider this is a deficiency of the pipeline, which leading to incomplete data collection. \
\

\i0\b Addressed: 
\b0 We have added a discussion of this point to the conclusion\'97in response to this comment and to R3.3, where Reviewer 3 asks about limitations of our methods. Our objective is to provide a scalable pipeline. While we agree that we could use Selenium to gather the dynamic content on any given site, we would need to customize the process for each website, whereas wget can be applied across sites without site-specific supervision. We acknowledge that this is a limitation of our process\'97perhaps the biggest limitation, and note that it is an open area for future research. 
\i \
\

\i0\b R1.4: 
\i\b0 Also, there is no need to use Selenium only to handle redirections.\
\

\i0\b Addressed:  
\b0 [MARKUS, WHAT CAN YOU SAY ABOUT THIS?]
\b \
\
R1.4: 
\i\b0 The authors removed boilerplate expressions line\'ad by\'adline after converting files into plain texts, but I am not sure how line \'adby\'adline elimination is effective, because inline elements (e.g. span tags) can occur in the same line as substantive content. They should have considered the nested structure of HTML documents for effective body text extraction. \
\

\i0\b Addressed: 
\b0 Since submitting the first version of the paper, we discovered the boilerpipe algorithm, which is very effective at extracting substantive blocks of text from websites (and has been tested and verified in published work). We abandoned our initial line-by-line approach in favor of using boilerpipe. Of course, we did not create boilerpipe. However, from what we can tell, it has not yet been used in political science (which we note in the paper), and we do ease its application to government website files through its incorporation in the gov2text package.
\b \
\
R1.5:
\i\b0  It is strange to remove tokens before applying POS\'adtagger (spaCy), because accurate lemmatization requires syntactical parsing of the original texts.\
\

\i0\b Addressed: 
\b0 We agree with this criticism, and have now moved lemmatization up in the processing pipeline, as is made clear in Table 3.
\i \
\

\i0\b Reviewer 2\

\i\b0 \

\i0\b R2.1: 
\i\b0 \cf5 I think the manuscript would be better suited for PA as a letter focused on the toolchain and explicitly aim at a broader audience than researchers working with local government documents.
\i0\b  
\i\b0 Revised into that form, it would work better if it would give more information on why and how the various components of the toolchain are preferable over the alternatives, and what are their limitations.\
\

\i0\b Addressed: 
\b0 We have revised the paper to be formatted as a letter focused on the toolchain. Our intention is to focus on government websites in general, with the running application of city websites. We removed much of the theoretical discussion of local government websites, and retain just enough to make sense of the running application. Since there are 8-10 separate tools in the toolchain, we do not have room to engage each one with a detailed comparison of alternatives. However, one improvement along these lines is that we now use a well established (and published) method for website boilerplate removal, so we can at least reference previous work regarding the effectiveness of that methodology.
\i \
\

\i0\b R2.2: 
\i\b0 Perhaps the most important instance are the various methods for boilerplate identification, currently relegated to footnote 11. Here, it would help the manuscript\'92s case a good deal if it could show how boilerplate removal matters for substantive conclusions, and show this not only for the analyzed corpus but also for some published findings. \
\

\i0\b Addressed: \
\
Reviewer 3
\i\b0 \
\

\i0\b R3.1: 
\i\b0 This article is a useful set of practices to help create a data\'adsource for local politics. However, the way that it\'92s written right now it seems more appropriate for a note than a full article. \
\

\i0\b \cf3 Addressed: 
\b0 We have reformatted the article as a letter.\cf5 \cb1 \

\i \cb4 \

\i0\b R3.2: 
\i\b0 Gathering data in local politics is difficult and recent efforts such as the LEAP project, and Sumner, Farris and Holman\'92s crowdsourcing method aim to make that process more access to scholars studying local and state politics. This website method could supplement these efforts and help scholars in the US (and abroad) study processes at the level where most people interact with the state \'96 at the local level. 
\i0 \cb1 \

\i \cb4 \

\i0\b \cf3 Addressed: 
\i\b0 \cf5 \
\

\i0\b \cb1 R3.3: 
\i\b0 \cb4 The authors talk about the improvements over other methods that they are offering, but are there drawbacks as well? 
\i0 \cb1 \
\

\b \cf3 \cb4 Addressed: 
\b0 The biggest limitation in our methodology is the reliance on wget to collect content from government websites. This method misses dynamic content displayed via JavaScript (i.e., a table populated by querying a database). We added a paragraph to the conclusion in which we discuss this limitation, and call for it to be addressed in future research.\cf5 \cb1 \
\

\b R3.4: 
\i\b0 \cb4 The topic modeling has no valence attached, so while the modeling can speak to broad categories that are being mentioned, can it also enable scholars to say something about credit claiming or blame attribution? Can we say something about the absence of terms across different types of municipalities? Right now, the article uses the partisanship of the mayor as a way to test whether websites across municipalities differ. This doesn\'92t seem to be the most useful example since most offices that people vote for in the US are non\'adpartisan and the data here can speak to a great deal of other things that may define information cities share with citizens and the broader public. \
\

\i0\b \cf3 Addressed:
\i\b0 \cf5 \
\

\i0\b R3.5: 
\i\b0 If the authors want to stay with the local politics example, it would be helpful to have a running example of a city throughout the text to show each step along the way. \
\

\i0\b \cf3 Addressed: 
\b0 We have added an example involving a message from the Mayor of Gary, IN that is depicted on the city's homepage. The mayor presents a very clear policy message on the homepage, which we depict in a screenshot. We then show how a naive text extraction from that site would include mostly menu items and links to other parts of the website (i.e., boilerplate). Finally, we show how, using the boilerplate elimination method we suggest isolates the Mayor's message---the only substantive text on the page. 
\i \cf5 \
\

\i0\b R3.6:
\i  
\b0 In addition, the topic model technique should allow the authors to say something about the topics that occur in websites along multiple dimensions that they already have measures of like city size, region, median income.
\i0\b \cb1  
\b0 \
\

\b \cf3 \cb4 Addressed:
\b0 \cf5 \cb1 \
\

\b R3.7:
\i  
\b0 \cb4 It would also be helpful to have a table or a figure that lays out the steps from pre\'adprocessing to topic modeling along with all of the R packages so that it\'92s more of a user guide for readers. 
\i0 \cb1 \
\

\b \cf3 \cb4 Addressed: 
\b0 We have added a table to the paper (Table 3) in which we list the steps in the pipeline, the software on which each step depends, and indicate whether the step is incorporated into our R package, gov2text.\cf5 \cb1 \
\

\i \cf3 \cb4 \
\
}